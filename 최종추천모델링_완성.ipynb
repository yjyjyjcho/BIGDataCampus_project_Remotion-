{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"최종추천모델링_완성","provenance":[],"collapsed_sections":[],"mount_file_id":"1oD3uXT1W82qPvhOoz0cmpAKYTMfudf3T","authorship_tag":"ABX9TyNJWUcK8GKY/29xJmLQ9uHC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"yh6lFWdBokDd","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","\n","rc = pd.read_excel('cont_result.xlsx')\n","rr = pd.read_csv('rating_sampling.csv')\n","\n","ret_senti = rr\n","ret_senti = ret_senti.drop(['index'], axis=1) #이 줄은 한번만 돌릴것\n","\n","\n","###################################################################################\n","####################while문 시작########################################################\n","#########################################################################################\n","\n","##모델 합치기 input 모델링###\n","\n","\n","def app_sent(ret_senti, sentiment):\n","  min = 1\n","  for i in range(ret_senti.shape[0]):\n","    for j in range(ret_senti.shape[1]):\n","      if ret_senti.iloc[i, j] == np.nan:\n","        continue\n","      else:\n","        mse = (sentiment-ret_senti.iloc[i, j])**2\n","\n","      if min > mse:\n","        min = mse\n","        row = i\n","        col = j\n","\n","  return row, ret_senti.columns[col]\n","# row = userid\n","# col = cafeid\n","###################################################################################\\\n","#######################행렬 분해 잠재요인 협업 추천##########################################\n","############################################################################\n","\n","\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","\n","def get_rmse(R, P, Q, non_zeros):\n","    error = 0\n","    # 두개의 분해된 행렬 P와 Q.T의 내적 곱으로 예측 R 행렬 생성\n","    full_pred_matrix = np.dot(P, Q.T)\n","    \n","    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n","    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n","    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n","    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n","    \n","    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n","      \n","    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n","    rmse = np.sqrt(mse)\n","    \n","    return rmse\n","\n","def matrix_factorization(R, K, steps=50, learning_rate=0.01, r_lambda = 0.01):\n","    num_users, num_items = R.shape\n","    # P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 랜덤한 값으로 입력합니다. \n","    np.random.seed(1)\n","    P = np.random.normal(scale=1./K, size=(num_users, K))\n","    Q = np.random.normal(scale=1./K, size=(num_items, K))\n","\n","    break_count = 0\n","       \n","    # R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트 객체에 저장. \n","    non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n","   \n","    # SGD기법으로 P와 Q 매트릭스를 계속 업데이트. \n","    for step in range(steps):\n","        for i, j, r in non_zeros:\n","            # 실제 값과 예측 값의 차이인 오류 값 구함\n","            eij = r - np.dot(P[i, :], Q[j, :].T)\n","            # Regularization을 반영한 SGD 업데이트 공식 적용\n","            P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n","            Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n","       \n","        rmse = get_rmse(R, P, Q, non_zeros)\n","        if (step % 10) == 0 :\n","            print(\"### iteration step : \", step,\" rmse : \", rmse)\n","            \n","    return P, Q\n","\n","import pandas as pd\n","import numpy as np\n","\n","ratings_matrix = ret_senti ##@#$%^@##데이터셋 소환\n","ratings_matrix = ratings_matrix.fillna(0)\n","\n","P, Q = matrix_factorization(ratings_matrix.values, K=50, steps=50, learning_rate=0.01, r_lambda = 0.01)\n","pred_matrix = np.dot(P, Q.T)\n","\n","\n","ratings_pred_matrix = pd.DataFrame(data=pred_matrix, index= ratings_matrix.index,\n","                                   columns = ratings_matrix.columns)\n","\n","ratings_pred_matrix.head(3)\n","\n","\n","\n","def get_ungone_cafe(ratings_matrix, userId):\n","    # userId로 입력받은 사용자의 모든 영화정보 추출하여 Series로 반환함. \n","    # 반환된 user_rating 은 영화명(title)을 index로 가지는 Series 객체임. \n","    user_rating = ratings_matrix.loc[userId,:]\n","    \n","    # user_rating이 0보다 크면 기존에 관람한 영화임. 대상 index를 추출하여 list 객체로 만듬\n","    already_gone = user_rating[ user_rating > 0].index.tolist()\n","    \n","    # 모든 영화명을 list 객체로 만듬. \n","    cafe_list = ratings_matrix.columns.tolist()\n","    \n","    # list comprehension으로 already_seen에 해당하는 movie는 movies_list에서 제외함. \n","    ungone_list = [ cafe for cafe in cafe_list if cafe not in already_gone]\n","    \n","    return ungone_list\n","\n","def recomm_cafe_by_userid(pred_df, userId, ungone_list, top_n=116):\n","    # 예측 평점 DataFrame에서 사용자id index와 ungone_list로 들어온 영화명 컬럼을 추출하여\n","    # 가장 예측 평점이 높은 순으로 정렬함. \n","    recomm_cafe = pred_df.loc[userId, ungone_list].sort_values(ascending=False)[:top_n]\n","    return recomm_cafe\n","\n","#=============================================================================\n","# 웹으로부터 입력\n","sentiment = 0.1 #input()#\n","row, col_name = app_sent(ret_senti, sentiment) #데이터셋 소환\n","# ============================================================================\n","# 사용자가 관람하지 않는 영화명 추출   \n","ungone_list = get_ungone_cafe(ratings_matrix, row)\n","\n","# 아이템 기반의 인접 이웃 협업 필터링으로 영화 추천 ###인풋값\n","recomm_cafe = recomm_cafe_by_userid(ratings_pred_matrix, row, ungone_list, top_n=116)\n","\n","# 평점 데이타를 DataFrame으로 생성. ###인풋값\n","recomm_cafe = pd.DataFrame(data=recomm_cafe.values,index=recomm_cafe.index,columns=['pred_score'])\n","recomm_cafe\n","\n","print(row, col_name) ###행렬분해 잠재요인 협업 추천 리스트\n","\n","\n","####################################################################################\n","###########################################################################################\n","#######################컨텐츠 기반_메뉴#########################################\n","########################################################################################\n","########################################################################\n","import pandas as pd\n","import numpy as np\n","import warnings; warnings.filterwarnings('ignore')\n","\n","cafe_df = rc[['검색어', '메뉴', 'sentiment', 'count']]\n","\n","\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# CountVectorizer를 적용하기 위해 공백문자로 word 단위가 구분되는 문자열로 변환. \n","cafe_df['menu_literal'] = cafe_df['메뉴'].apply(lambda x : ('').join(x))\n","count_vect = CountVectorizer(min_df=0, ngram_range=(1,2))\n","menu_mat = count_vect.fit_transform(cafe_df['menu_literal'])\n","cafe_df['menu_mat'] = count_vect.fit_transform(cafe_df['menu_literal'])\n","\n","print(menu_mat.shape)\n","print('\\n')\n","\n","from sklearn.metrics.pairwise import cosine_similarity\n","menu_sim = cosine_similarity(menu_mat, menu_mat)\n","# print(menu_sim.shape)\n","# print('\\n')\n","\n","# print(menu_sim[:2])\n","# print('\\n')\n","menu_sim_sorted_ind = menu_sim.argsort()[:, ::-1]\n","# print(menu_sim_sorted_ind[:1])\n","# print('\\n')\n","\n","def find_sim_cafe(df, sorted_ind, title_name, top_n=116):\n","    # 인자로 입력된 movies_df DataFrame에서 'title' 컬럼이 입력된 title_name 값인 DataFrame추출\n","    name_cafe = df[df['검색어'] == title_name]\n","    # title_named을 가진 DataFrame의 index 객체를 ndarray로 반환하고 \n","    # sorted_ind 인자로 입력된 genre_sim_sorted_ind 객체에서 유사도 순으로 top_n 개의 index 추출\n","    title_index = name_cafe.index.values\n","    similar_indexes = sorted_ind[title_index, :(top_n)]\n","    # 추출된 top_n index들 출력. top_n index는 2차원 데이터 임. \n","    #dataframe에서 index로 사용하기 위해서 1차원 array로 변경\n","    similar_indexes = similar_indexes.reshape(-1)\n","    return df.iloc[similar_indexes].sort_values(ascending=False)[:top_n]\n","\n","# # def find_sim_cafe(df, sorted_ind, title_name, top_n=116):\n","# #     title_cafe = df[df['검색어'] == title_name]\n","# #     title_index = title_cafe.index.values\n","# #     # top_n의 2배에 해당하는 쟝르 유사성이 높은 index 추출 \n","# #     similar_indexes = sorted_ind[title_index, :(top_n)]\n","# #     similar_indexes = similar_indexes.reshape(-1)\n","# #     # 기준 영화 index는 제외\n","# #     similar_indexes = similar_indexes[similar_indexes != title_index]\n","# #     # top_n의 2배에 해당하는 후보군에서 weighted_vote 높은 순으로 top_n 만큼 추출 \n","# #     return df.iloc[similar_indexes].sort_values('weighted_vote', ascending=False)[:top_n]\n","\n","# # similar_cafe = find_sim_cafe(cafe_df, menu_sim_sorted_ind, row,10)\n","# # similar_cafe[['검색어', 'sentiment']]\n","\n","################################################################################################\n","#########################################투표 보정식#############################################\n","###########################################################################################\n","\n","C = cafe_df['sentiment'].mean()\n","m = cafe_df['count'].quantile(0.6)\n","print('C:',round(C,3), 'm:',round(m,3))\n","print('\\n')\n","\n","\n","\n","percentile = 0.6\n","m = cafe_df['count'].quantile(percentile)\n","C = cafe_df['sentiment'].mean()\n","\n","def weighted_vote_average(record):\n","    v = record['count']\n","    R = record['sentiment']\n","    \n","    return ( (v/(v+m)) * R ) + ( (m/(m+v)) * C )   \n","\n","cafe_df['weighted_vote'] = cafe_df.apply(weighted_vote_average, axis=1)\n","\n","\n","\n","cafe_df[['검색어','sentiment','weighted_vote','count']].sort_values('weighted_vote', ascending=False)[:116]\n","\n","\n","def find_sim_cafe(df, sorted_ind, title_name, top_n=116):\n","    title_cafe = df[df['검색어'] == title_name]\n","    title_index = title_cafe.index.values\n","    # top_n의 2배에 해당하는 쟝르 유사성이 높은 index 추출 \n","    similar_indexes = sorted_ind[title_index, :(top_n)]\n","    similar_indexes = similar_indexes.reshape(-1)\n","    # 기준 영화 index는 제외\n","    similar_indexes = similar_indexes[similar_indexes != title_index]\n","    # top_n의 2배에 해당하는 후보군에서 weighted_vote 높은 순으로 top_n 만큼 추출 \n","    return df.iloc[similar_indexes].sort_values('weighted_vote', ascending=False)[:top_n]\n","\n","print('\\n')\n","similar_cafe = find_sim_cafe(cafe_df, menu_sim_sorted_ind, col_name,116)\n","print(similar_cafe[['검색어', 'sentiment', 'weighted_vote']]) ##컨텐츠 기반 추천 리스트\n","# print(menu_mat)\n","\n","#################################################################################################\n","###############################마무리##############################################################\n","###############################################################################################\n","df = similar_cafe[['검색어', 'weighted_vote']]\n","\n","df2 = recomm_cafe.reset_index()\n","df2.columns = ['검색어', 'pred_score']\n","df2\n","\n","\n","###while문 돌아가면서 m비율에서 n비율로 가중치가 증가하도록#######################\n","\n","m=7 #컨텐츠기반\n","n=3 #행렬분해잠재요인\n","df3 = pd.merge(df, df2, how='left', on='검색어')\n","df3['final'] = df3['weighted_vote']*m + df3['pred_score']*n\n","a = df3.sort_values('final', ascending=False)[:10] \n","\n","print(a['검색어']) #최종 모델 리스트"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cq54jXNOooBm","colab_type":"code","colab":{}},"source":["df = pd.read_csv(\"./DATASET/project/샘플링 전 데셋/df_ratings_senti.csv\") ###주피터 코드"],"execution_count":null,"outputs":[]}]}
